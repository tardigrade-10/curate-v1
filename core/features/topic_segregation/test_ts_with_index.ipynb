{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic segregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "curpath = os.getcwd()\n",
    "os.chdir(curpath.split(\"core\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Any, Tuple, Union\n",
    "\n",
    "from prompts import SIMPLE_TS_PROMPTS, SIMPLE_TS_WITH_REF_PROMPTS\n",
    "from core.features.topic_segregation.utils import add_dicts, calculate_cost_gpt4_8k, calculate_cost_gpt4_omni\n",
    "from core.features.provider import creator, text_creator_defaults\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_from_raw_text(raw_text, sep = \"\\n\"):\n",
    "\n",
    "    if isinstance(raw_text, str):\n",
    "        raw_text = raw_text.replace(\"’\", \"'\")\n",
    "        raw_text_list = raw_text.split(sep)\n",
    "    \n",
    "    elif isinstance(raw_text, list):\n",
    "        raw_text_list = raw_text\n",
    "    return list(set(raw_text_list))\n",
    "\n",
    "def treat_output_for_json(input):\n",
    "    out = \"{\" + input.split(\"{\")[1].split(\"}\")[0] + \"}\"\n",
    "    # out = out.replace('\\'', '\"')\n",
    "    # out = out.replace('\\\\\"', '\\'')\n",
    "    return out\n",
    "\n",
    "def chunk_raw_text_list(raw_text_list, max_len=3000):\n",
    "\n",
    "    text_list = []\n",
    "    char_len = 0\n",
    "    ind_text_list = []\n",
    "\n",
    "    for text in raw_text_list:\n",
    "\n",
    "        l = len(text)\n",
    "        char_len += l\n",
    "        if char_len > max_len:\n",
    "            text_list.append(ind_text_list)\n",
    "            ind_text_list = []\n",
    "            ind_text_list.append(text)\n",
    "            char_len = 0\n",
    "            char_len += l\n",
    "        else:\n",
    "            ind_text_list.append(text)\n",
    "\n",
    "    text_list.append(ind_text_list)\n",
    "    return text_list\n",
    "\n",
    "# provides indexed dict_text and text_dict \n",
    "def get_indexed_text_and_dict(text_list):\n",
    "\n",
    "    indexed_text = []\n",
    "    text_dict = {}\n",
    "    for i, text in enumerate(text_list):\n",
    "        if not text or text == '':\n",
    "            continue\n",
    "\n",
    "        mod = f\"{i}: {text}\"\n",
    "\n",
    "        indexed_text.append(mod)\n",
    "        text_dict[i] = text\n",
    "\n",
    "    return indexed_text, text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_topic_segregation(raw_text = None, n = 1, topics = None, complete_seg = True):\n",
    "\n",
    "    if raw_text is None:\n",
    "        raise ValueError(\"raw_text must be provided\")\n",
    "\n",
    "    # if topics is None:\n",
    "    #     conversation = [{\"role\": \"system\", \"content\": SIMPLE_TS_PROMPTS}]\n",
    "\n",
    "    #     user_prompt = f\"\"\"\n",
    "    #     RAW_TEXT:\n",
    "\n",
    "    #     //raw//\n",
    "\n",
    "    #     {raw_text}\n",
    "\n",
    "    #     //raw//\n",
    "\n",
    "    #     OUTPUT:\n",
    "    #     \"\"\"\n",
    "\n",
    "    if topics is not None:\n",
    "        conversation = [{\"role\": \"system\", \"content\": SIMPLE_TS_WITH_REF_PROMPTS}]\n",
    "\n",
    "        n = len(topics)\n",
    "        reference = {\"number of classes to segregate\": n, \"topics\": topics, \"segregate all provided text\": complete_seg}\n",
    "\n",
    "        user_prompt = f\"\"\"\n",
    "        RAW_TEXT:\n",
    "\n",
    "        //raw//\n",
    "\n",
    "        {raw_text}\n",
    "\n",
    "        //raw//\n",
    "\n",
    "        REFERENCE:\n",
    "        {str(reference)}\n",
    "\n",
    "        OUTPUT:\n",
    "        \"\"\"\n",
    "\n",
    "    user_message = {'role': 'user', \"content\": user_prompt}\n",
    "    conversation.append(user_message)\n",
    "\n",
    "    response = creator(**text_creator_defaults,\n",
    "                        messages = conversation,\n",
    "                     )\n",
    "    \n",
    "    total_usage = dict(response.usage)\n",
    "\n",
    "    output = response.choices[0].message.content\n",
    "\n",
    "    return {\"output\": output, \"total_usage\": total_usage}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics Segregation with reference and indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Kyiv expects 'positive' EU report on membership bid: Ukraine minister - Hindustan Times\\n\", \"Judge Halts Trump's 'Irrelevant' Answers In Valuation Inquiry - Times Now\\n\", \"Jordan says 'all options' open as Israel-Hamas war intensifies - Hindustan Times\\n\", 'Israel-Hamas War Live Updates: Gaza death toll goes past 10,000 as Israel divides city in 2 parts after encircling it - The Indian Express\\n', 'Who can qualify for the last two Cricket World Cup semifinal spots and how? - Al Jazeera English\\n', 'Croatia Minister Tries To Kiss German Counterpart At EU Meet, Apologises Later - NDTV\\n', 'World News in Brief: Sudan and South Sudan updates, Ukraine heritage under fire in Odesa - UN News\\n', 'Britain`s loneliest sheep rescued, but her future home remains uncertain - WION\\n', 'Choking New Delhi smog shutters schools and shrouds Cricket World Cup - CNN\\n', 'World News in Brief: Russia pulls out of nuclear test ban treaty ... - Department of Political and Peacebuilding Affairs\\n', \"World News in Brief: Protection call for refugees in Pakistan, 'One ... - UN News\\n\", \"If Hezbollah attacks Israel, US 'prepared to intervene militarily': Report - Hindustan Times\\n\", \"China, Australia can become 'trusting' partners, Xi Jinping says - Hindustan Times\\n\", 'Israel hails US nuclear submarine deployment in region: ‘Good news’ - Hindustan Times\\n', \"Russia's 'terrorism' warning from Israel-Hamas war: ‘Will face radicalisation’ - Hindustan Times\\n\", \"Royal Expert warns Meghan's memoir could deepen strained relations - Hindustan Times\\n\", 'World In Pictures | November 6, 2023 - Times Now\\n', 'World News in Brief: Reducing disaster risk for persons with ... - Department of Political and Peacebuilding Affairs\\n', 'Stocks to Watch: SBI, Cello World, IndiGo, Bank of Baroda, L&T, IDFC First Bank | Mint - Mint\\n', 'Cello World share price dips after strong debut. Opportunity to buy? | Mint - Mint\\n', 'Donald Trump decries ‘political warfare’ in NY business fraud case - The Indian Express\\n', 'Gaza-Egypt Rafah border crossing reopened for evacuations, Hamas says - Hindustan Times\\n', \"US says 'thousands' of civilians killed or wounded in Gaza - Hindustan Times\\n\", 'Pakistan airbase Miyanwali under attack, 9 militants killed in response - Hindustan Times\\n', 'Netanyahu says no ceasefire till hostages return; Iran arrests ‘Israeli spies’ - Hindustan Times\\n', 'Livemint is now the fastest-growing news website in the world: Press Gazette | Mint - Mint\\n', 'World News in Brief: recovery efforts in Ukraine, human rights in ... - UN News\\n', \"Israeli minister says atomic bomb on Gaza 'an option’; Netanyahu reacts - Hindustan Times\\n\", 'Top 10 world news: Gaza aid stuck at border with Egypt, Israel prepares for two-front war? and more - WION\\n', 'Nijjar killing probe ‘tainted’, ‘show evidence’: Indian envoy to Canada - Hindustan Times\\n', 'Israel shows ‘proof’: Hamas using Qatar, Indonesia-funded hospitals for hiding - Hindustan Times\\n', 'One Israeli killed in Hezbollah attack on border: Israel military - Hindustan Times\\n', \"World News in Brief: UN 'committed' to aid Ukraine, blue helmets exit ... - UN News\\n\", 'Top 10 world news: Death toll in Israel-Hamas war crosses 1,300, & more - WION\\n', 'ICC World Cup 2023 Points Table: India Dominates, South Africa Chases, and Semi-final Scenarios Unfold | Mint - Mint\\n', 'World News in Brief, Afghanistan rights abuses, Sudan crisis ... - UN News\\n', 'Top 10 world news: Israel-Hamas war updates, death toll after missile strike in Hroza rises to 59, and more - WION\\n', \"‘SHAMEFUL’: Netizens scream at Shakib as Sri Lanka's Angelo Mathews becomes first player to be ‘timed out’ | Mint - Mint\\n\", 'Over 300 Americans, US residents evacuated from Gaza: White House - Hindustan Times\\n', 'World News in Brief: Sandstorm alert, albinism and climate change ... - UN News\\n', \"What is Israel's next move in its war against Hamas? - Sky News\\n\", 'Reuters World News Summary - Devdiscourse\\n', \"November 6 Morning Brief: Today's Top news and headlines from cricket world - CricTracker\\n\", \"World News in Brief: Femicide 'pandemic', war crimes appeal to ... - UN News\\n\", \"Killer Whales ‘attack and sink' yacht off the coast of Morocco - Hindustan Times\\n\", 'World News in Brief: 500 million heading into extreme poverty ... - UN News\\n', 'Top 10 world news: Rockets fired from Gaza towards Israel, Putin says Israel conflict `example` of US failure - WION\\n', \"Obama calls Hamas attack 'Horrific', addresses Palestinian situation - Hindustan Times\\n\", 'West Indies T20 World Cup winner announces international retirement - ICC Cricket\\n', \"Delhi Air 12 Times Worse Than 'Hiroshima-Like' Gaza - Times Now\\n\"]\n",
      "4424\n",
      "50\n",
      "2\n",
      "33\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "with open(\"core/features/topic_segregation/test_data/news1.txt\", 'rb') as f:\n",
    "    _text = f.readlines()\n",
    "\n",
    "_text = [x.decode('utf-8') for x in _text]\n",
    "r_text = \"\".join(_text)\n",
    "\n",
    "print(_text)\n",
    "print(len(r_text))\n",
    "\n",
    "# convert raw_text to list and get unique values\n",
    "unique_text_list = get_unique_from_raw_text(_text, sep=\"\\n\")\n",
    "print(len(unique_text_list))\n",
    "\n",
    "indexed_text, text_dict = get_indexed_text_and_dict(unique_text_list)\n",
    "\n",
    "# chunking the list into sublists with max length of characters in a chunk is 3000\n",
    "chunked_text_list = chunk_raw_text_list(indexed_text, max_len=3000)\n",
    "\n",
    "print(len(chunked_text_list))\n",
    "for i in chunked_text_list:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input = 1000 chars - 1 rupee\n",
    "output = 1 rupee per request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.42"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.42 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_tokens': 1928, 'completion_tokens': 136, 'prompt_tokens': 1792}\n",
      "0.022\n",
      "Topic: Sports\n",
      "['7', '15', '33', '34', '39', '43']\n",
      "\n",
      "Topic: Defence\n",
      "['1', '2', '3', '8', '11', '18', '19', '21', '24', '25', '26', '28', '29', '30', '32', '38', '40', '41', '44', '48']\n",
      "\n",
      "Topic: Regional:India\n",
      "['10', '20', '35', '36', '37', '45', '47', '49']\n",
      "\n",
      "West Indies T20 World Cup winner announces international retirement - ICC Cricket\n",
      "\n",
      "\n",
      "ICC World Cup 2023 Points Table: India Dominates, South Africa Chases, and Semi-final Scenarios Unfold | Mint - Mint\n",
      "\n",
      "\n",
      "Choking New Delhi smog shutters schools and shrouds Cricket World Cup - CNN\n",
      "\n",
      "\n",
      "‘SHAMEFUL’: Netizens scream at Shakib as Sri Lanka's Angelo Mathews becomes first player to be ‘timed out’ | Mint - Mint\n",
      "\n",
      "\n",
      "November 6 Morning Brief: Today's Top news and headlines from cricket world - CricTracker\n",
      "\n",
      "\n",
      "Who can qualify for the last two Cricket World Cup semifinal spots and how? - Al Jazeera English\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# final batch processing function\n",
    "def ts_batch_process(topics: List, input_text: List[List], complete_seg = False) -> [Dict, Dict]:\n",
    "\n",
    "    final_dict = {topic:[] for topic in topics}\n",
    "    total_tokens = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}\n",
    "\n",
    "    for raw_text_list in input_text:\n",
    "        raw_text = \"\\n\".join(raw_text_list)\n",
    "\n",
    "        result = generate_topic_segregation(raw_text=raw_text, topics=topics, complete_seg=complete_seg)\n",
    "        output = result['output']\n",
    "        tokens = result['total_usage']\n",
    "\n",
    "        try:\n",
    "            json_out = json.loads(output)\n",
    "        except:\n",
    "            raise ValueError(\"Output is not a valid JSON\")\n",
    "        # print(json_out)\n",
    "        final_dict = add_dicts(final_dict, json_out)\n",
    "        total_tokens = add_dicts(total_tokens, tokens)\n",
    "\n",
    "    return final_dict, total_tokens\n",
    "\n",
    "\n",
    "topics = [\"Sports\", \"Defence\", \"Regional:India\"]\n",
    "res, tokens = ts_batch_process(topics, chunked_text_list, complete_seg=False)\n",
    "\n",
    "print(tokens)\n",
    "print(calculate_cost_gpt4_omni(tokens))\n",
    "for topic in topics:\n",
    "    print(f\"Topic: {topic}\")\n",
    "    print(res[topic])\n",
    "    print()\n",
    "\n",
    "for i in res[topics[0]]:\n",
    "    print(text_dict[int(i)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Earthquake tremors felt in Delhi-NCR again - IndiaTimes\\r\\n', \"'Yeh planning se hota hai...': Wasim Akram on India's unbeaten run in World Cup - IndiaTimes\\r\\n\", '‘More people are willing to pay more money for Indian artworks’ | Mint - Mint\\r\\n', 'UK springs EV surprise in FTA talks with India | Mint - Mint\\r\\n', \"India's online gaming industry gains with increased user spending | Mint - Mint\\r\\n\", 'Aakash Chopra reacts as Gurpatwant Pannun warns Air India passengers - Hindustan Times\\r\\n', \"India-Canada row: Diplomatic standoff continues; experts say ‘relationship in deep crisis' | 10 points | Mint - Mint\\r\\n\", \"Canada carrying out 'tainted' Nijjar probe: Indian envoy Sanjay Verma - IndiaTimes\\r\\n\", \"High-Level Canadian Official Damaged Probe In Hardeep Nijjar's Killing: Indian Envoy - NDTV\\r\\n\", 'Australia orders ex-Indian envoy to pay hefty compensation to former domestic help for alleged exploitation - WION\\r\\n', 'Australia court asks ex-India envoy to pay ₹74L to former help - IndiaTimes\\r\\n', 'Ex-Indian envoy asked to pay compensation to former house help: Report - Hindustan Times\\r\\n', 'Breaking News, November 6 | HIGHLIGHTS - India TV News\\r\\n', 'Operation Cactus: When India prevented a coup in Maldives - The Indian Express\\r\\n', 'India records eight new Covid cases - IndiaTimes\\r\\n', \"India TV Sports Wrap on November 6: Today's top 10 trending news stories - India TV News\\r\\n\", 'Breaking news LIVE: Gaza war death toll tops 10,000 - The Financial Express\\r\\n', 'India, Bhutan agree on new initiatives to bolster trade, connectivity - Hindustan Times\\r\\n', 'Morning brief: India slams Canada over Nijjar row, and all the latest news - Hindustan Times\\r\\n', \"India-Nepal border forces hold talks, discuss 'mutual issues' - IndiaTimes\\r\\n\", \"Ahead of Diwali, PM Modi pushes for 'vocal for local' - IndiaTimes\\r\\n\", 'The double-whammy from India’s falling farm exports - The Indian Express\\r\\n', 'This company is critical to the success of India’s smartphone revolution | Mint - Mint\\r\\n', 'Manipur govt looks at restoring mobile internet in peaceful areas - The Indian Express\\r\\n', 'NITI weighs discontinuing key water report launched 5 years ago - The Indian Express\\r\\n', 'Double-decker buses making a comeback in India - Hindustan Times\\r\\n', 'India most targeted country with 13.7% of cyberattacks: Report - India TV News\\r\\n', 'Odd-even rule in Delhi from November 13-20 amid worsening air ... - IndiaTimes\\r\\n', 'Centre blocks 22 betting apps, including Mahadev - IndiaTimes\\r\\n', 'Fresh round of electoral bond sale begins today - IndiaTimes\\r\\n', \"Akhilesh Yadav calls INDIA bloc partner Congress 'chalu' party - Hindustan Times\\r\\n\", 'Grand Tamasha: Understanding India’s stance on Israel-Hamas conflict - Hindustan Times\\r\\n', 'Two teenagers go missing in Manipur; phones recovered: Police - Hindustan Times\\r\\n', 'Evening briefing: EC rejects plea on INDIA acronym - Hindustan Times\\r\\n', 'Indian sports news wrap, November 6 - Sportstar\\r\\n', 'South Africa ‘nicely cleaned up’ by India: Jonty Rhodes’ hilarious remark after massive defeat | Mint - Mint\\r\\n', 'ATC books $322 mn goodwill impairment charge for India unit - ETTelecom\\r\\n', 'Aaj Ki Baat: Full episode, November 6, 2023 - India TV News\\r\\n', \"Evening briefing: Kharge's 'Jawans of PM Modi' jibe - Hindustan Times\\r\\n\", 'India News Updates: PM Modi, Sundar Pichai discusses expanding electronics manufacturing ecosystem in India - Economic Times\\r\\n', 'Dehradun’s three-day Crime Literature Festival concludes - The Indian Express\\r\\n', 'Heeralal Samariya appointed as chief information commissioner - Hindustan Times\\r\\n', 'China-based Arctech installs 6 GW solar trackers in India - ETEnergyWorld\\r\\n', 'India highest ranked after Germany in women’s Olympic qualifiers - IndiaTimes\\r\\n', 'Fitch raises India medium-term growth estimate by 70bps, cuts China’s as much - The Financial Express\\r\\n', 'Is India vs Pakistan World Cup final match possible? Here’s the roadmap to the dream encounter | Mint - Mint\\r\\n', 'How Many Hours Do Indians Work Every Week? Report Shows Interesting Data - NDTV\\r\\n', 'India justified in accusing Canada of neglect: Pankaj Saran - The Indian Express\\r\\n', 'Wavemaker India announces key appointments, Marketing ... - ETBrandEquity\\r\\n', 'Congress announces third list of 16 candidates for Telangana polls - IndiaTimes\\r\\n']\n",
      "50\n",
      "2\n",
      "36\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "with open(\"core/features/topic_segregation/test_data/news2.txt\", 'rb') as f:\n",
    "    _text = f.readlines()\n",
    "\n",
    "_text = [x.decode('utf-8') for x in _text]\n",
    "\n",
    "print(_text)\n",
    "\n",
    "# convert raw_text to list and get unique values\n",
    "unique_text_list = get_unique_from_raw_text(_text, sep=\"\\n\")\n",
    "print(len(unique_text_list))\n",
    "\n",
    "indexed_text, text_dict = get_indexed_text_and_dict(unique_text_list)\n",
    "\n",
    "# chunking the list into sublists with max length of characters in a chunk is 3000\n",
    "chunked_text_list = chunk_raw_text_list(indexed_text, max_len=3000)\n",
    "\n",
    "print(len(chunked_text_list))\n",
    "for i in chunked_text_list:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completion_tokens': 119, 'total_tokens': 1803, 'prompt_tokens': 1684}\n",
      "0.057659999999999996\n",
      "Topic: Sports\n",
      "['7', '12', '22', '26', '35', '36', '37']\n",
      "\n",
      "Topic: Defence\n",
      "['2', '3', '13', '14', '32', '33']\n",
      "\n",
      "Topic: Technology\n",
      "['4', '6', '11', '16', '23', '29', '42', '43', '46']\n",
      "\n",
      "Topic: Elections\n",
      "['17', '18', '19', '41']\n",
      "\n",
      "India TV Sports Wrap on November 6: Today's top 10 trending news stories - India TV News\n",
      "\n",
      "\n",
      "India highest ranked after Germany in women’s Olympic qualifiers - IndiaTimes\n",
      "\n",
      "\n",
      "Is India vs Pakistan World Cup final match possible? Here’s the roadmap to the dream encounter | Mint - Mint\n",
      "\n",
      "\n",
      "Aakash Chopra reacts as Gurpatwant Pannun warns Air India passengers - Hindustan Times\n",
      "\n",
      "\n",
      "Indian sports news wrap, November 6 - Sportstar\n",
      "\n",
      "\n",
      "'Yeh planning se hota hai...': Wasim Akram on India's unbeaten run in World Cup - IndiaTimes\n",
      "\n",
      "\n",
      "South Africa ‘nicely cleaned up’ by India: Jonty Rhodes’ hilarious remark after massive defeat | Mint - Mint\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# final batch processing function\n",
    "def ts_batch_process(topics: List, input_text: List[List], complete_seg = False) -> [Dict, Dict]:\n",
    "\n",
    "    final_dict = {topic:[] for topic in topics}\n",
    "    total_tokens = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}\n",
    "\n",
    "    for raw_text_list in input_text:\n",
    "        raw_text = \"\\n\".join(raw_text_list)\n",
    "\n",
    "        result = generate_topic_segregation(raw_text=raw_text, topics=topics, complete_seg=complete_seg)\n",
    "        output = result['output']\n",
    "        tokens = result['total_usage']\n",
    "\n",
    "        try:\n",
    "            json_out = json.loads(output)\n",
    "        except:\n",
    "            print(\"GOT ERROR IN JSON LOADING\")\n",
    "            out = treat_output_for_json(output)\n",
    "            json_out = json.loads(out)\n",
    "        # print(json_out)\n",
    "        final_dict = add_dicts(final_dict, json_out)\n",
    "        total_tokens = add_dicts(total_tokens, tokens)\n",
    "\n",
    "    return final_dict, total_tokens\n",
    "\n",
    "\n",
    "topics = [\"Sports\", \"Defence\", \"Technology\", \"Elections\"]\n",
    "res, tokens = ts_batch_process(topics, chunked_text_list, complete_seg=False)\n",
    "\n",
    "print(tokens)\n",
    "print(calculate_cost_gpt4_8k(tokens))\n",
    "for topic in topics:\n",
    "    print(f\"Topic: {topic}\")\n",
    "    print(res[topic])\n",
    "    print()\n",
    "\n",
    "for i in res[topics[0]]:\n",
    "    print(text_dict[int(i)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "3\n",
      "35\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "with open(\"core/features/topic_segregation/test_data/news3.txt\", 'rb') as f:\n",
    "    _text = f.readlines()\n",
    "\n",
    "_text = [x.decode('utf-8') for x in _text]\n",
    "\n",
    "# print(_text)\n",
    "\n",
    "# convert raw_text to list and get unique values\n",
    "unique_text_list = get_unique_from_raw_text(_text, sep=\"\\n\")\n",
    "print(len(unique_text_list))\n",
    "\n",
    "indexed_text, text_dict = get_indexed_text_and_dict(unique_text_list)\n",
    "\n",
    "# chunking the list into sublists with max length of characters in a chunk is 3000\n",
    "chunked_text_list = chunk_raw_text_list(indexed_text, max_len=3000)\n",
    "\n",
    "print(len(chunked_text_list))\n",
    "for i in chunked_text_list:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completion_tokens': 168, 'total_tokens': 3317, 'prompt_tokens': 3149}\n",
      "0.03653\n",
      "Topic: Sports\n",
      "['13', '25', '35', '50', '57', '79', '91']\n",
      "\n",
      "Topic: Defence\n",
      "['8', '22', '32', '44', '54', '61', '69', '73', '74', '78', '89']\n",
      "\n",
      "Topic: Technology\n",
      "['0', '38', '46', '52', '64', '71', '85', '92']\n",
      "\n",
      "Topic: Elections\n",
      "['9', '12', '40', '41', '42', '43', '53', '59', '67', '87']\n",
      "\n",
      "E\n",
      "Entire Sri Lanka Cricket Board sacked after humiliating World Cup loss to India - Hindustan Times\n",
      "\n",
      "IND vs SA | A record equalled and an Indian win — a perfect birthday gift for Kohli - The Hindu\n",
      "\n",
      "Afternoon briefing: Sanjay Raut's India vs Pakistan match dig - Hindustan Times\n",
      "\n",
      "\"Ben Stokes should skip last two World Cup matches and return ... - Crictoday.com (Cricket News) \n",
      "\n",
      "Lanka sacks entire Cricket Board following humiliating defeat against India - Business Standard\n",
      "\n",
      "India 8, Pak 0: Dominance on the big stage continues - Hindustan Times\n",
      "\n",
      "Cricket World Cup Latest Points Table, Highest Run-Scorer, Wicket-Taker List After India vs South Africa WC Match - ABP Live\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# final batch processing function\n",
    "def ts_batch_process(topics: List, input_text: List[List], complete_seg = False) -> [Dict, Dict]:\n",
    "\n",
    "    final_dict = {topic:[] for topic in topics}\n",
    "    total_tokens = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}\n",
    "\n",
    "    for raw_text_list in input_text:\n",
    "        raw_text = \"\\n\".join(raw_text_list)\n",
    "\n",
    "        result = generate_topic_segregation(raw_text=raw_text, topics=topics, complete_seg=complete_seg)\n",
    "        output = result['output']\n",
    "        tokens = result['total_usage']\n",
    "\n",
    "        try:\n",
    "            json_out = json.loads(output)\n",
    "        except:\n",
    "            print(\"GOT ERROR IN JSON LOADING\")\n",
    "            out = treat_output_for_json(output)\n",
    "            json_out = json.loads(out)\n",
    "        # print(json_out)\n",
    "        final_dict = add_dicts(final_dict, json_out)\n",
    "        total_tokens = add_dicts(total_tokens, tokens)\n",
    "\n",
    "    return final_dict, total_tokens\n",
    "\n",
    "\n",
    "topics = [\"Sports\", \"Defence\", \"Technology\", \"Elections\"]\n",
    "res, tokens = ts_batch_process(topics, chunked_text_list, complete_seg=False)\n",
    "\n",
    "print(tokens)\n",
    "print(calculate_cost_gpt4_omni(tokens))\n",
    "for topic in topics:\n",
    "    print(f\"Topic: {topic}\")\n",
    "    print(res[topic])\n",
    "    print()\n",
    "\n",
    "print(topic[0])\n",
    "for i in res[topics[0]]:\n",
    "    print(text_dict[int(i)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "4\n",
      "28\n",
      "28\n",
      "27\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "with open(\"core/features/topic_segregation/test_data/news_data_raj.txt\", 'rb') as f:\n",
    "    _text = f.readlines()\n",
    "\n",
    "_text = [x.decode('utf-8') for x in _text]\n",
    "\n",
    "# print(_text)\n",
    "\n",
    "# convert raw_text to list and get unique values\n",
    "unique_text_list = get_unique_from_raw_text(_text, sep=\"\\n\")\n",
    "print(len(unique_text_list))\n",
    "\n",
    "indexed_text, text_dict = get_indexed_text_and_dict(unique_text_list)\n",
    "\n",
    "# chunking the list into sublists with max length of characters in a chunk is 3000\n",
    "chunked_text_list = chunk_raw_text_list(indexed_text, max_len=3000)\n",
    "\n",
    "print(len(chunked_text_list))\n",
    "for i in chunked_text_list:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completion_tokens': 389, 'total_tokens': 6478, 'prompt_tokens': 6089}\n",
      "0.07256\n",
      "Topic: Sports\n",
      "[]\n",
      "\n",
      "Topic: Defence\n",
      "[]\n",
      "\n",
      "Topic: Technology\n",
      "[]\n",
      "\n",
      "Topic: Elections\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']\n",
      "\n",
      "E\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# final batch processing function\n",
    "def ts_batch_process(topics: List, input_text: List[List], complete_seg = False) -> [Dict, Dict]:\n",
    "\n",
    "    final_dict = {topic:[] for topic in topics}\n",
    "    total_tokens = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}\n",
    "\n",
    "    for raw_text_list in input_text:\n",
    "        raw_text = \"\\n\".join(raw_text_list)\n",
    "\n",
    "        result = generate_topic_segregation(raw_text=raw_text, topics=topics, complete_seg=complete_seg)\n",
    "        output = result['output']\n",
    "        tokens = result['total_usage']\n",
    "\n",
    "        try:\n",
    "            json_out = json.loads(output)\n",
    "        except:\n",
    "            print(\"GOT ERROR IN JSON LOADING\")\n",
    "            out = treat_output_for_json(output)\n",
    "            json_out = json.loads(out)\n",
    "        # print(json_out)\n",
    "        final_dict = add_dicts(final_dict, json_out)\n",
    "        total_tokens = add_dicts(total_tokens, tokens)\n",
    "\n",
    "    return final_dict, total_tokens\n",
    "\n",
    "\n",
    "topics = [\"Sports\", \"Defence\", \"Technology\", \"Elections\"]\n",
    "res, tokens = ts_batch_process(topics, chunked_text_list, complete_seg=False)\n",
    "\n",
    "print(tokens)\n",
    "print(calculate_cost_gpt4_omni(tokens))\n",
    "for topic in topics:\n",
    "    print(f\"Topic: {topic}\")\n",
    "    print(res[topic])\n",
    "    print()\n",
    "\n",
    "print(topic[0])\n",
    "for i in res[topics[0]]:\n",
    "    print(text_dict[int(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curate-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
