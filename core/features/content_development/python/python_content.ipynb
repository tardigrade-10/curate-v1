{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "curpath = os.getcwd()\n",
    "os.chdir(curpath.split(\"core\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "import asyncio\n",
    "from typing import List, Dict, Any, Tuple, Union\n",
    "\n",
    "from core.features.content_development.python.prompts import SIMPLE_COURSE_GENERATION_PROMPT, JUPYTER_NOTEBOOK_TUTORIAL_PROMPT\n",
    "from core.features.topic_segregation.utils import add_dicts, calculate_cost_gpt4_8k, calculate_cost_gpt4_turbo\n",
    "from core.features.provider import async_creator, text_model_defaults\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FLOW - \n",
    "1. generate a course structure after asking for a topic, scope of the topic, duration of course (in hours), parts (modules)\n",
    "format ```json \n",
    "\n",
    "{\n",
    "    \"topic\": \"topic\",\n",
    "    \"curriculum\": {\n",
    "        \"module1\" : [list of subtopics in module1],\n",
    "        \"module2\" : [list of subtopics in module2],\n",
    "            ...\n",
    "    },\n",
    "}\n",
    "\n",
    "2. take first topic of module1, and ask for the content on it with proper comments and explanations. add all the response in different files and iterate for all the topics of all the modules. \n",
    "\n",
    "\n",
    "pseudo code - \n",
    "\n",
    "\n",
    "structure = generate_structure(topic, topic_scope, duration_in_hours, number_of_parts)\n",
    "\n",
    "for module in structure[\"curriculum\"]:\n",
    "    for topic in structure[\"curriculum\"][module]:\n",
    "        content = generate_content(topic)\n",
    "        save_content(content)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_course_structure(title:str, scope:str, duration:int, num_modules:int, format=None):\n",
    "\n",
    "    conversation = [{\"role\": \"system\", \"content\": SIMPLE_COURSE_GENERATION_PROMPT}]\n",
    "\n",
    "    user_input = f\"\"\"\n",
    "    topic: {title}\n",
    "    scope: {scope}\n",
    "    duration: {duration}\n",
    "    num_modules: {num_modules}\n",
    "    \"\"\"\n",
    "\n",
    "    user_message = {'role': 'user', 'content': user_input}\n",
    "    conversation.append(user_message)\n",
    "\n",
    "    response = await async_creator(\n",
    "        **text_model_defaults,\n",
    "        messages=conversation\n",
    "        )\n",
    "    \n",
    "    output = response.choices[0].message.content\n",
    "    total_usage = response.usage\n",
    "\n",
    "    return {\"output\": output, \"total_usage\": total_usage}\n",
    "\n",
    "\n",
    "async def generate_content_notebook(curriculum, previous_part, current_topic):\n",
    "\n",
    "    conversation = [{\"role\": \"system\", \"content\": JUPYTER_NOTEBOOK_TUTORIAL_PROMPT}]\n",
    "\n",
    "    user_input = f\"\"\"\n",
    "    curriculum = {curriculum},\n",
    "\n",
    "    previous_part = {previous_part},\n",
    "\n",
    "    current_part = {current_topic}\n",
    "    \"\"\"\n",
    "\n",
    "    user_message = {'role': 'user', 'content': user_input}\n",
    "    conversation.append(user_message)\n",
    "\n",
    "    response = await async_creator(\n",
    "        **text_model_defaults,\n",
    "        messages=conversation\n",
    "        )\n",
    "    \n",
    "    output = response.choices[0].message.content\n",
    "    total_usage = response.usage\n",
    "\n",
    "    return {\"output\": output, \"total_usage\": total_usage}\n",
    "\n",
    "\n",
    "def convert_to_jupyter_notebook(input_json, file_name):\n",
    "\n",
    "    # Template for a Jupyter Notebook\n",
    "\n",
    "    \"\"\"\n",
    "    Rules to create the jupyter notebook:\n",
    "    1. metadata tag must be present in code cell\n",
    "    \"\"\"\n",
    "    notebook_template = {\n",
    "        \"cells\": [],\n",
    "        \"metadata\": {'kernelspec': {'display_name': 'Python 3',\n",
    "            'language': 'python',\n",
    "            'name': 'python3'},\n",
    "            'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
    "            'file_extension': '.py',\n",
    "            'mimetype': 'text/x-python',\n",
    "            'name': 'python',\n",
    "            'nbconvert_exporter': 'python',\n",
    "            'pygments_lexer': 'ipython3',\n",
    "            'version': '3.8.5'}},\n",
    "        \"nbformat\": 4,\n",
    "        \"nbformat_minor\": 4\n",
    "    }\n",
    "\n",
    "    # Adding the cells from the input JSON to the notebook template\n",
    "    for cell in input_json['cells']:\n",
    "        if cell['cell_type'] == \"code\":\n",
    "            cell['metadata'] = {}\n",
    "\n",
    "    notebook_template['cells'] = input_json['cells']\n",
    "\n",
    "    with open(f'{file_name}.json', 'w') as file:\n",
    "        json.dump(notebook_template, file, indent=2)\n",
    "\n",
    "        \n",
    "result = asyncio.run(generate_course_structure(title=\"Generative Adversarial Networks with Tensorflow\", scope=\"Neural Networks to GANs\", duration=10, num_modules=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def content_pipeline(title, curriculum, path):\n",
    "\n",
    "    previous_part = \"NA\"\n",
    "    for module, topics in curriculum['curriculum'].items():\n",
    "        for topic in topics:\n",
    "            # Assuming generate_content_notebook and convert_to_jupyter_notebook are asynchronous\n",
    "            result = await generate_content_notebook(curriculum=curriculum, previous_part=previous_part, current_topic=topic)\n",
    "            content_json = json.loads(result['output'])\n",
    "\n",
    "            convert_to_jupyter_notebook(content_json, os.path.join(path, title.replace(\" \", \"_\"), module, topic.replace(\" \", \"_\") + \".ipynb\"))\n",
    "\n",
    "            previous_part = content_json\n",
    "\n",
    "        print(\"Module\" + str(i+1) + \" of \" + str(len(curriculum['curriculum'])) + \" completed\")\n",
    "    print(\"Content pipeline completed\")\n",
    "\n",
    "\n",
    "title = result['output']['title']\n",
    "curriculum = result['output']['curriculum']\n",
    "\n",
    "asyncio.run(content_pipeline(title=title, curriculum=curriculum, path=\"content_development\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Generative Adversarial Networks with Tensorflow',\n",
       " 'curriculum': {'module1': ['Introduction to Neural Networks',\n",
       "   'Fundamentals of Deep Learning',\n",
       "   'Activation Functions',\n",
       "   'Loss Functions',\n",
       "   'Backpropagation and Gradient Descent',\n",
       "   'Tensorflow Basics'],\n",
       "  'module2': ['Convolutional Neural Networks (CNNs)',\n",
       "   'CNN Architectures',\n",
       "   'Tensorflow for CNNs',\n",
       "   'Image Processing and Generation',\n",
       "   'Feature Extraction and Transfer Learning'],\n",
       "  'module3': ['Introduction to Generative Models',\n",
       "   'Autoencoders',\n",
       "   'Variational Autoencoders (VAEs)',\n",
       "   'Introduction to Generative Adversarial Networks (GANs)'],\n",
       "  'module4': ['GAN Architectures and Applications',\n",
       "   'Designing and Training GANs with Tensorflow',\n",
       "   'Advanced GANs (DCGAN, CGAN, etc.)',\n",
       "   'Challenges in Training GANs',\n",
       "   'Project: Building and Training a GAN with Tensorflow']}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_notebook = json.loads(result['output'])\n",
    "\n",
    "curriculum = raw_notebook\n",
    "\n",
    "curriculum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_content_notebook(curriculum, previous_part, current_topic):\n",
    "\n",
    "    conversation = [{\"role\": \"system\", \"content\": JUPYTER_NOTEBOOK_TUTORIAL_PROMPT}]\n",
    "\n",
    "    user_input = f\"\"\"\n",
    "    curriculum = {curriculum},\n",
    "\n",
    "    previous_part = {previous_part},\n",
    "\n",
    "    current_part = {current_topic}\n",
    "    \"\"\"\n",
    "\n",
    "    user_message = {'role': 'user', 'content': user_input}\n",
    "    conversation.append(user_message)\n",
    "\n",
    "    response = creator(\n",
    "        **text_model_defaults,\n",
    "        messages=conversation\n",
    "        )\n",
    "    \n",
    "    output = response.choices[0].message.content\n",
    "    total_usage = response.usage\n",
    "\n",
    "    return {\"output\": output, \"total_usage\": total_usage}\n",
    "\n",
    "\n",
    "result = generate_content_notebook(curriculum=curriculum, previous_part=\"NA\", current_topic=\"Introduction to Neural Networks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'source': '# Introduction to Neural Networks\\n\\nIn this section, we will dive into the foundational concepts of neural networks, which are the building blocks of deep learning and the technology behind many modern artificial intelligence applications.'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'source': '## What is a Neural Network?\\n\\nA neural network is a computational model inspired by the way biological neural networks in the human brain process information. It consists of a large number of interconnected processing elements called neurons that work together to solve specific problems. Neural networks are used for a variety of tasks, such as image and speech recognition, language translation, and playing games, among others.'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'source': \"## Components of a Neural Network\\n\\n- **Neurons**: The basic unit of a neural network, often called a node or perceptron, which receives input, processes it, and generates an output.\\n- **Weights**: Parameters within the neural network that transform input data within the network's layers.\\n- **Biases**: Additional parameters which are added to the weighted input before applying the neuron's activation function.\\n- **Activation Function**: A mathematical function applied to the neuron's output to introduce non-linearity into the network, allowing it to learn complex patterns.\\n- **Layers**: Groups of neurons that perform calculations. A neural network typically consists of an input layer, one or more hidden layers, and an output layer.\"},\n",
       "  {'cell_type': 'markdown',\n",
       "   'source': '## How Does a Neural Network Learn?\\n\\nA neural network learns by adjusting its weights and biases through a process called training. During training, the network is fed with a large amount of labeled data and uses an algorithm to minimize the difference between its predicted output and the actual output. The most common algorithm used for this purpose is called backpropagation combined with an optimization technique such as gradient descent.'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'source': '## Types of Neural Networks\\n\\nThere are various types of neural networks designed for different tasks:\\n\\n- **Feedforward Neural Networks (FNNs)**: The simplest type of neural network where the connections between the nodes do not form a cycle.\\n- **Recurrent Neural Networks (RNNs)**: Networks with loops allowing information to be persisted, useful for sequential data like time series or natural language.\\n- **Convolutional Neural Networks (CNNs)**: Designed for processing data with a grid-like topology, such as images, by using convolutional layers.\\n- **Autoencoders**: Used for unsupervised learning tasks, such as feature learning and dimensionality reduction.\\n- **Generative Adversarial Networks (GANs)**: Composed of two networks, a generator and a discriminator, that are trained simultaneously through adversarial processes to generate new data samples.'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'source': '## Neural Network Architectures\\n\\nThe architecture of a neural network refers to the arrangement of neurons and layers. This includes the number of layers, the number of neurons in each layer, and how the neurons are connected to each other. The choice of architecture depends on the complexity of the task and the type of data being processed.'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'source': '## Applications of Neural Networks\\n\\nNeural networks have a wide range of applications including, but not limited to:\\n\\n- **Computer Vision**: Image classification, object detection, image generation.\\n- **Natural Language Processing (NLP)**: Machine translation, sentiment analysis, text generation.\\n- **Speech Recognition**: Transcribing spoken language into text, voice user interfaces.\\n- **Gaming**: Non-player character (NPC) behavior, procedural content generation.\\n- **Healthcare**: Disease diagnosis, medical image analysis, drug discovery.'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'source': '## Summary\\n\\nIn this introduction, we have covered the basics of what neural networks are, their components, how they learn, different types, architectures, and applications. In the following sections, we will delve deeper into the fundamentals of deep learning and explore how to implement these concepts using TensorFlow.'}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = json.loads(result['output'])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'source': \"# Fundamentals of Deep Learning\\n\\nDeep learning is a subset of machine learning that uses neural networks with many layers (hence 'deep') to model complex patterns in data. In this section, we will explore the core concepts that underpin deep learning, including the architecture of deep networks, the role of data, and the algorithms that drive learning.\"},\n",
       "  {'cell_type': 'markdown',\n",
       "   'source': '## What is Deep Learning?\\n\\nDeep learning is a machine learning technique that teaches computers to learn by example, just as humans do. It is a key technology behind driverless cars, enabling them to recognize a stop sign, or distinguishing a pedestrian from a lamppost. It is the key to voice control in consumer devices like phones, tablets, TVs, and hands-free speakers. Deep learning is getting lots of attention lately and for good reason. It’s achieving results that were not possible before.'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'source': '## Key Concepts in Deep Learning\\n\\n- **Artificial Neural Networks (ANNs)**: The foundation of deep learning models, inspired by the biological neural networks.\\n- **Deep Neural Networks (DNNs)**: ANNs with multiple hidden layers that can model complex data with high levels of abstraction.\\n- **Hyperparameters**: Settings that can be tuned to control the learning process, such as learning rate, number of layers, and number of neurons per layer.\\n- **Overfitting and Underfitting**: Phenomena where a model is too complex or too simple to generalize well from the training data to unseen data.\\n- **Regularization**: Techniques to prevent overfitting, such as dropout, weight decay, and data augmentation.\\n- **Optimization Algorithms**: Methods used to update weights in the network, such as Stochastic Gradient Descent (SGD), Adam, and RMSprop.'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'source': '## Deep Learning Architectures\\n\\nThere are several architectures in deep learning, each designed for specific kinds of problems:\\n\\n- **Multilayer Perceptrons (MLPs)**: The simplest form of DNNs, suitable for tabular data.\\n- **Convolutional Neural Networks (CNNs)**: Designed for image data, they use convolutional layers to capture spatial hierarchies.\\n- **Recurrent Neural Networks (RNNs)**: Suitable for sequential data, such as time series or text.\\n- **Long Short-Term Memory Networks (LSTMs)**: A type of RNN that can learn long-term dependencies, useful for more complex sequence tasks.\\n- **Transformer Networks**: Based on self-attention mechanisms, they have become the state-of-the-art for many NLP tasks.'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'source': '## Training Deep Neural Networks\\n\\nTraining a deep neural network involves several steps:\\n\\n1. **Data Preprocessing**: Preparing and cleaning the data to make it suitable for use in a neural network.\\n2. **Weight Initialization**: Choosing an initial set of weights, often randomly, before training begins.\\n3. **Forward Propagation**: Passing input data through the network to obtain an output.\\n4. **Loss Calculation**: Measuring the difference between the predicted output and the actual target values.\\n5. **Backpropagation**: Calculating the gradient of the loss function with respect to each weight by the chain rule.\\n6. **Weight Update**: Adjusting the weights of the network in the direction that reduces the loss, using an optimization algorithm.'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'source': \"## Challenges in Deep Learning\\n\\nDeep learning models come with their own set of challenges:\\n\\n- **Computational Resources**: Deep learning models often require significant computational power and memory.\\n- **Data Requirements**: Large amounts of labeled data are needed to train deep learning models effectively.\\n- **Interpretability**: Deep learning models are often seen as 'black boxes' with complex inner workings that are difficult to interpret.\\n- **Adversarial Examples**: Inputs to deep learning models that are intentionally designed to cause the model to make a mistake.\"},\n",
       "  {'cell_type': 'markdown',\n",
       "   'source': '## Applications of Deep Learning\\n\\nDeep learning has been successfully applied to a variety of domains, including:\\n\\n- **Image and Video Recognition**: From facial recognition to medical image analysis.\\n- **Natural Language Processing**: For tasks such as translation, sentiment analysis, and summarization.\\n- **Autonomous Vehicles**: Enabling cars to perceive their environment and make decisions.\\n- **Game Playing**: AI that can play complex games like Go and Chess at superhuman levels.\\n- **Speech Recognition and Generation**: Powering virtual assistants and real-time translation services.'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'source': '## Summary\\n\\nIn this section, we have introduced the fundamentals of deep learning, including its definition, key concepts, architectures, training processes, challenges, and applications. As we move forward, we will delve deeper into each of these areas and learn how to implement deep learning models using TensorFlow.'}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result = generate_content_notebook(curriculum=curriculum, previous_part=output, current_topic='Fundamentals of Deep Learning')\n",
    "output = json.loads(result['output'])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completion_tokens': 1112, 'prompt_tokens': 1291, 'total_tokens': 2403}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04627"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage = result['total_usage'].model_dump()\n",
    "\n",
    "print(usage)\n",
    "\n",
    "calculate_cost_gpt4_turbo(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def convert_to_jupyter_notebook(input_json, file_name):\n",
    "\n",
    "    # Template for a Jupyter Notebook\n",
    "\n",
    "    \"\"\"\n",
    "    Rules to create the jupyter notebook:\n",
    "    1. metadata tag must be present in code cell\n",
    "    \"\"\"\n",
    "    notebook_template = {\n",
    "        \"cells\": [],\n",
    "        \"metadata\": {'kernelspec': {'display_name': 'Python 3',\n",
    "            'language': 'python',\n",
    "            'name': 'python3'},\n",
    "            'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
    "            'file_extension': '.py',\n",
    "            'mimetype': 'text/x-python',\n",
    "            'name': 'python',\n",
    "            'nbconvert_exporter': 'python',\n",
    "            'pygments_lexer': 'ipython3',\n",
    "            'version': '3.8.5'}},\n",
    "        \"nbformat\": 4,\n",
    "        \"nbformat_minor\": 4\n",
    "    }\n",
    "\n",
    "    # Adding the cells from the input JSON to the notebook template\n",
    "    for cell in input_json['cells']:\n",
    "        if cell['cell_type'] == \"code\":\n",
    "            cell['metadata'] = {}\n",
    "\n",
    "    notebook_template['cells'] = input_json['cells']\n",
    "\n",
    "    with open(f'{file_name}.json', 'w') as file:\n",
    "        json.dump(notebook_template, file, indent=2)\n",
    "\n",
    "\n",
    "# Convert to Jupyter Notebook JSON\n",
    "jupyter_notebook_json = convert_to_jupyter_notebook(output, file_name='deep_learning_fundamentals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curate-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
