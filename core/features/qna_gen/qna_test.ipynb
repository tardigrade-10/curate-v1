{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### this notebooks has the sample code for the qna generation functions and calculations checks with optimized code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "curpath = os.getcwd()\n",
    "os.chdir(curpath.split(\"core\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "from prompts import SIMPLE_NUMERICAL_MCQ_PROMPT, SIMPLE_TEXTUAL_TEXT_MCQ_PROMPT, SIMPLE_CONCEPTUAL_TEXT_MCQ_PROMPT, CALCULATION_CHECK_PROMPT\n",
    "from helper import function_definitions, get_results_from_wolfram_cloud\n",
    "from utils import add_dicts\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_results_from_wolfram_cloud',\n",
       "  'description': 'Use this function for problems solvable with Wolfram Language code.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'queries': {'type': 'string',\n",
       "     'description': 'the input wolfram language query for mathematical calculations in string. ONLY proper wolfram language queries are supported. Format for Query: \"a = Solve[aCoeff1*aVar == Var1 - Offset1 && aCoeff2*aVar == Var1 + Offset2, {aVar, Var1}][[1, 1, 2]]\".'}}},\n",
       "  'required': ['queries']}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions = [function_definitions[\"get_results_from_wolfram_cloud\"]] \n",
    "\n",
    "functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conceptual Text MCQ Generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### theory will be the context text for conceptual questions. context will be used for textual/assessment type questions.\n",
    "\n",
    "def generate_conceptual_text_mcqs(theory=None, n=1, examples = None, model_id = \"gpt-4-0613\"):\n",
    "\n",
    "    conversation = [{\"role\": \"system\", \"content\": SIMPLE_CONCEPTUAL_TEXT_MCQ_PROMPT}]\n",
    "\n",
    "    if theory is None:\n",
    "        raise ValueError(\"No theory provided\")\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    TOPIC_THEORY:\n",
    "    //theory//\n",
    "\n",
    "    {theory}\n",
    "\n",
    "    //theory//\n",
    "   \n",
    "    N: {n}\n",
    "\n",
    "    EXAMPLE:\n",
    "    {examples if examples else \"Not Provided\"}\n",
    "\n",
    "    QUESTIONS: \n",
    "    \"\"\"\n",
    "\n",
    "    user_message = {'role': 'user', \"content\": user_prompt}\n",
    "    conversation.append(user_message)\n",
    "    \n",
    "    total_usage = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}\n",
    "    response = openai.ChatCompletion.create(\n",
    "                                    model= model_id,\n",
    "                                    messages = conversation,\n",
    "                                    temperature = 1\n",
    "                                    )\n",
    "    \n",
    "    total_usage = add_dicts(total_usage, dict(response.usage))\n",
    "    output = response.choices[0].message.content\n",
    "    \n",
    "    return {\"output\": output, \"total_usage\": total_usage}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory = \"\"\"\n",
    "Thermodynamics\n",
    "\n",
    "Definitions:\n",
    "1. System: A part of the universe under study.\n",
    "2. Surroundings: Everything other than the system.\n",
    "3. Thermodynamic State: The description of a system in terms of properties like pressure, volume, temperature, etc.\n",
    "4. State Functions: Properties that depend only on the state of the system, not the path. Examples: U (Internal energy), H (Enthalpy), S (Entropy), and G (Gibbs free energy).\n",
    "5. Path Functions: Depend on the path taken during a change, like heat (q) and work (w).\n",
    "6. First Law of Thermodynamics: ΔU = q + w, where ΔU is the change in internal energy, q is heat, and w is work.\n",
    "7. Isothermal Process: Process in which temperature remains constant.\n",
    "8. Adiabatic Process: No heat exchange with surroundings. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "examples = {\n",
    "        \"question\": \"Which of the following statements is true regarding thermodynamics?\",\n",
    "        \"choices\": {\"a\": \"The surroundings refer to the part of the universe under study.\", \"b\": \"State Functions depend on the path taken during a change.\", \"c\": \"In an adiabatic process, there is no heat exchange with the surroundings.\", \"d\": \"The First Law of Thermodynamics is represented by the equation ΔU = q - w.\"},\n",
    "        \"answer\": {\"c\": \"In an adiabatic process, there is no heat exchange with the surroundings\"}\n",
    "    }\n",
    "\n",
    "output = generate_conceptual_text_mcqs(\n",
    "                        theory = theory,\n",
    "                        n = 3\n",
    "                        # examples = examples,\n",
    "                        )\n",
    "\n",
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual Text MCQ Generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# context will be the context text for textual questions. context will be used for textual/assessment type questions.\n",
    "def generate_textual_text_mcqs(context=None, n=1, examples = None, model_id = \"gpt-4-0613\"):\n",
    "\n",
    "    if theory is None:\n",
    "        raise ValueError(\"context must be provided\")\n",
    "    \n",
    "\n",
    "    conversation = [{\"role\": \"system\", \"content\": SIMPLE_TEXTUAL_TEXT_MCQ_PROMPT}]\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    CONTEXT_TEXT:\n",
    "    //context//\n",
    "\n",
    "    {context}\n",
    "\n",
    "    //context//\n",
    "\n",
    "    N: {n}\n",
    "\n",
    "    EXAMPLES:\n",
    "    {str(examples) if examples else \"Not Provided\"}\n",
    "\n",
    "    QUESTIONS: \n",
    "    \"\"\"\n",
    "\n",
    "    user_message = {'role': 'user', \"content\": user_prompt}\n",
    "    conversation.append(user_message)\n",
    "\n",
    "    total_usage = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}\n",
    "    response = openai.ChatCompletion.create(\n",
    "                                    model= model_id,\n",
    "                                    messages = conversation,\n",
    "                                    temperature = 1\n",
    "                                    )\n",
    "    \n",
    "    total_usage = add_dicts(total_usage, dict(response.usage))\n",
    "\n",
    "    output = response.choices[0].message.content\n",
    "\n",
    "    return {\"output\": output, \"total_usage\": total_usage}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    {\n",
      "        \"mcqs\": [\n",
      "            {\n",
      "            \"question\": \"What is the main problem raised by the author regarding the use of import relief laws?\",\n",
      "            \"choices\": {\"a\": \"They benefit foreign governments.\", \"b\": \"They may be used against U.S. companies by foreign competitors.\", \"c\": \"They discourage companies from establishing overseas plants.\", \"d\": \"They prevent domestic companies from dumping their products at less than fair value.\"},\n",
      "            \"answer\": {\"b\": \"They may be used against U.S. companies by foreign competitors.\"}\n",
      "            },\n",
      "            {\n",
      "            \"question\": \"Who was claiming injury in the case of dumping rock salt by Canadian companies?\",\n",
      "            \"choices\": {\"a\": \"A U.S. company with overseas operations\", \"b\": \"A foreign conglomerate with U.S. operations\", \"c\": \"A Canadian company\", \"d\": \"A Chicago-based firm\"},\n",
      "            \"answer\": {\"b\": \"A foreign conglomerate with U.S. operations\"}\n",
      "            }\n",
      "        ]\n",
      "    }\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"Many United States companies have, unfortunately, made the search for legal protection from import competition into a major line of work. Since 1980 the United States International Trade Commission (ITC) has received about 280 complaints alleging damage from imports that benefit foreign governments’ subsidies. Another 340 charge that foreign companies “dumped” their products in the United States at “less than fair value.” Even when no unfair practices are alleged, the simple claim that an industry has been injured by imports is sufficient grounds to seek relief.\n",
    "\n",
    "Contrary to the general impression, this quest for import relief has hurt more companies than it has helped. As corporations begin to function globally, they develop an intricate web of marketing, production, and research relationships, The complexity of these relationships makes it unlikely that a system of import relief laws will meet the strategic needs of all the units under the same parent company.\n",
    "\n",
    "Internationalization increases the danger that foreign companies will use import relief laws against the very companies the laws were designed to protect. Suppose a United States-owned company establishes an overseas plant to manufacture a product while its competitor makes the same product in the United States. If the competitor can prove injury from the imports—and that the United States company received a subsidy from a foreign government to build its plant abroad—the United States company’s products will be uncompetitive in the United States, since they would be subject to duties.\n",
    "\n",
    "Perhaps the most brazen case occurred when the ITC investigated allegations that Canadian companies were injuring the United States salt industry by dumping rock salt, used to de-ice roads. The bizarre aspect of the complaint was that a foreign conglomerate with United States operations was crying for help against a United States company with foreign operations. The “United States” company claiming the injury was a subsidiary of a Dutch conglomerate. In contrast, the “Canadian” companies included a subsidiary of a Chicago firm that was the second-largest domestic producer of rock salt.\"\"\"\n",
    "\n",
    "examples = {\n",
    "        \"question\": \"Which of the following options is most similar in meaning to the word: “Intricate” mentioned in the article?\",\n",
    "        \"choices\": {\"a\": \"Twisted\", \"b\": \"Straightforward\", \"c\": \"Simple\", \"d\": \"Advance\"},\n",
    "        \"answer\": {\"a\": \"Twisted\"}\n",
    "    }\n",
    "\n",
    "result = generate_textual_text_mcqs(context, n = 2, examples = examples)\n",
    "\n",
    "print(result[\"output\"])\n",
    "print(result[\"total_usage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_tokens': 1142, 'prompt_tokens': 931, 'completion_tokens': 211}\n"
     ]
    }
   ],
   "source": [
    "print(result[\"total_usage\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical MCQ Generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_numerical_mcqs(theory=None, n=1, examples = None, model_id = \"gpt-4-0613\"):\n",
    "\n",
    "    if theory is None:\n",
    "        raise ValueError(\"Theory must be provided\")\n",
    "\n",
    "    conversation = [{\"role\": \"system\", \"content\": SIMPLE_NUMERICAL_MCQ_PROMPT}]\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    TOPIC_THEORY:\n",
    "    //theory//\n",
    "\n",
    "    {theory}\n",
    "\n",
    "    //theory//\n",
    "\n",
    "    N: {n}\n",
    "\n",
    "    EXAMPLES:\n",
    "    {str(examples) if examples else \"Not Provided\"}\n",
    "\n",
    "    QUESTIONS: \n",
    "    \"\"\"\n",
    "\n",
    "    user_message = {'role': 'user', \"content\": user_prompt}\n",
    "    conversation.append(user_message)\n",
    "\n",
    "    total_usage = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}\n",
    "    response = openai.ChatCompletion.create(\n",
    "                                    model= model_id,\n",
    "                                    messages = conversation,\n",
    "                                    temperature = 1\n",
    "                                    )\n",
    "    \n",
    "    total_usage = add_dicts(total_usage, dict(response.usage))\n",
    "\n",
    "    output = response.choices[0].message.content\n",
    "\n",
    "    return {\"output\": output, \"total_usage\": total_usage}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory = \"\"\"\n",
    "Work Done in Various Processes:\n",
    "a. Isothermal Process (constant temperature):\n",
    "W = P(V2 - V1) * ln(V2 / V1)\n",
    "b. Adiabatic Process (no heat exchange):\n",
    "W = (P2V2 - P1V1) / (1 - γ), where γ is the adiabatic index\n",
    "c. Isobaric Process (constant pressure):\n",
    "W = P(V2 - V1)\"\"\"\n",
    "\n",
    "examples = {\n",
    "        \"question\": \"\"\"Consider three processes: isothermal, adiabatic, and isobaric. For a certain gas, the following data is given:\n",
    "\n",
    "Initial volume, V1 = 2 m^3\n",
    "Final volume, V2 = 4 m^3\n",
    "Initial pressure, P1 = 2 atm\n",
    "Final pressure, P2 = 3 atm\n",
    "Adiabatic index, γ = 1.4\n",
    "Calculate the work done during the adiabatic process.\"\"\",\n",
    "        \"choices\": {\"a\": \"-1.5 atm.m^3\", \"b\": \"-2.0 atm.m^3\", \"c\": \"-2.5 atm.m^3\", \"d\": \"-20.0 atm.m^3\"},\n",
    "        \"answer\": {\"d\": \"-20.0 atm.m^3\"}\n",
    "    }\n",
    "\n",
    "result = generate_numerical_mcqs(theory = theory, n = 2, examples = examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"mcqs\": [\n",
      "        {\n",
      "        \"question\": \"Calculate the work done during an isothermal process if the initial volume (V1) is 1 m^3, the final volume (V2) is 3 m^3 and the pressure is 1 atm.\",\n",
      "        \"choices\": {\"a\": \"0.367 atm.m^3\", \"b\": \"0.693 atm.m^3\", \"c\": \"1.098 atm.m^3\", \"d\": \"1.386 atm.m^3\"},\n",
      "        \"answer\": {\"b\": \"0.693 atm.m^3\"}\n",
      "        },\n",
      "        {\n",
      "        \"question\": \"Calculate the work done during an isobaric process if the initial volume (V1) is 1 m^3, the final volume (V2) is 5 m^3 and the pressure is 1 atm.\",\n",
      "        \"choices\": {\"a\": \"1 atm.m^3\", \"b\": \"2 atm.m^3\", \"c\": \"3 atm.m^3\", \"d\": \"4 atm.m^3\"},\n",
      "        \"answer\": {\"d\": \"4 atm.m^3\"}\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{'total_tokens': 905, 'prompt_tokens': 660, 'completion_tokens': 245}\n"
     ]
    }
   ],
   "source": [
    "print(result[\"output\"])\n",
    "print(result['total_usage'])\n",
    "\n",
    "json_ques = json.loads(result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculation check for numerical mcqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER FUNCTION {'total_tokens': 512, 'prompt_tokens': 485, 'completion_tokens': 27}\n",
      "CALLING FUNCTION\n",
      "QUERIES W = N[Integrate[1/x, {x, 1, 3}]]\n",
      "good queries W = N[Integrate[1/x, {x, 1, 3}]]\n",
      "RESULT FROM FUNCTION 1.0986122886681098\n",
      "{'total_tokens': 1163, 'prompt_tokens': 1018, 'completion_tokens': 145}\n",
      "\n",
      "AFTER FUNCTION {'total_tokens': 500, 'prompt_tokens': 476, 'completion_tokens': 24}\n",
      "CALLING FUNCTION\n",
      "QUERIES W = Integrate[1, {V, 1, 5}]\n",
      "good queries W = Integrate[1, {V, 1, 5}]\n",
      "RESULT FROM FUNCTION 4\n",
      "{'total_tokens': 1123, 'prompt_tokens': 990, 'completion_tokens': 133}\n",
      "['\\n    {\"question\": \"Calculate the work done during an isothermal process if the initial volume (V1) is 1 m^3, the final volume (V2) is 3 m^3 and the pressure is 1 atm.\", \"choices\": {\"a\": \"0.367 atm.m^3\", \"b\": \"0.693 atm.m^3\", \"c\": \"1.098 atm.m^3\", \"d\": \"1.386 atm.m^3\"}, \"answer\": {\"c\": \"1.098 atm.m^3\"}}', '\\n    {\"question\": \"Calculate the work done during an isobaric process if the initial volume (V1) is 1 m^3, the final volume (V2) is 5 m^3 and the pressure is 1 atm.\", \"choices\": {\"a\": \"1 atm.m^3\", \"b\": \"2 atm.m^3\", \"c\": \"3 atm.m^3\", \"d\": \"4 atm.m^3\"}, \"answer\": {\"d\": \"4 atm.m^3\"}}']\n"
     ]
    }
   ],
   "source": [
    "# calculation check and improvements\n",
    "\n",
    "def calculation_checking(input, model_id = \"gpt-4-0613\"):\n",
    "\n",
    "    conversation = [{\"role\": \"system\", \"content\": CALCULATION_CHECK_PROMPT}]\n",
    "    input_prompt = f\"\"\"\n",
    "\n",
    "    INPUT: \n",
    "\n",
    "    {input}\n",
    "\n",
    "    OUTPUT: \n",
    "\n",
    "    \"\"\" \n",
    "\n",
    "    input_message = {'role': 'user', 'content': input_prompt}\n",
    "    conversation.append(input_message)\n",
    "\n",
    "    total_usage = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}\n",
    "    response = openai.ChatCompletion.create(\n",
    "                                    model= model_id,\n",
    "                                    messages = conversation,\n",
    "                                    functions = functions,\n",
    "                                    function_call = {'name': \"get_results_from_wolfram_cloud\"},\n",
    "                                    temperature = 0\n",
    "                                )\n",
    "\n",
    "    total_usage = add_dicts(total_usage, dict(response.usage))\n",
    "    function_call = response.choices[0]['message']['function_call']\n",
    "    conversation.append(response.choices[0]['message'])\n",
    "\n",
    "    queries = json.loads(function_call[\"arguments\"])[\"queries\"]\n",
    "    try:\n",
    "        print(\"good queries\", queries)\n",
    "        result = get_results_from_wolfram_cloud(queries)\n",
    "    except:\n",
    "        raise Exception(\"error from wolfram\")\n",
    "\n",
    "    conversation.append({'role': 'function', \"name\": function_call[\"name\"], \"content\": str(result)})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = model_id,\n",
    "        messages = conversation,\n",
    "        functions = functions,\n",
    "        temperature = 0.2\n",
    "    )\n",
    "\n",
    "    total_usage = add_dicts(total_usage, dict(response.usage))\n",
    "    output = response.choices[0].message.content\n",
    "    return {\"output\": output, \"total_usage\": total_usage}\n",
    "\n",
    "correct_ques = []\n",
    "total_usage = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}\n",
    "for ques in list(json_ques.values())[0]:\n",
    "    ques = str(ques).replace(\"'\", '\"')\n",
    "    result = calculation_checking(ques)\n",
    "    total_usage = add_dicts(total_usage, result[\"total_usage\"])\n",
    "    correct_ques.append(result[\"output\"])\n",
    "    print(result[\"output\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Calculate the work done during an isothermal process if the initial volume (V1) is 1 m^3, the final volume (V2) is 3 m^3 and the pressure is 1 atm.',\n",
       " 'choices': {'a': '0.367 atm.m^3',\n",
       "  'b': '0.693 atm.m^3',\n",
       "  'c': '1.098 atm.m^3',\n",
       "  'd': '1.386 atm.m^3'},\n",
       " 'answer': {'c': '1.098 atm.m^3'}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(correct_ques[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curate-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
